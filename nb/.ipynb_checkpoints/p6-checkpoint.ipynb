{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f64853b-a8dc-4fb4-9917-29649e1a4d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address     Load        Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  172.21.0.4  185.41 KiB  16      100.0%            ab484865-e62b-4d27-9fae-d22e5005ea4e  rack1\n",
      "UN  172.21.0.2  243.52 KiB  16      100.0%            80bafe9b-0c72-4900-983b-8fd6a5d91e31  rack1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nodetool status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fed97e7-961f-4f1d-857e-fab5be6f2c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['p6-db-1', 'p6-db-2', 'p6-db-3'])\n",
    "cass = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf4b5280-5ced-407b-8f43-841245860290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f92d8284370>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"drop keyspace if exists weather\")\n",
    "cass.execute(\"\"\"create keyspace weather with replication = {\n",
    "    'class' : 'SimpleStrategy',\n",
    "    'replication_factor' : 3\n",
    "    };\n",
    "\"\"\")\n",
    "cass.execute(\"use weather\")\n",
    "cass.execute(\"\"\"\n",
    "    create type station_record(\n",
    "        tmin INT,\n",
    "        tmax INT\n",
    "    )\n",
    "\"\"\")\n",
    "cass.execute(\"\"\"\n",
    "    create table stations(\n",
    "        id TEXT,\n",
    "        name TEXT STATIC,\n",
    "        date DATE,\n",
    "        record WEATHER.STATION_RECORD,\n",
    "        PRIMARY KEY ((id), date)\n",
    "    ) WITH CLUSTERING ORDER BY (date ASC)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c06cdb-e25f-4783-b8ee-060bf82d170d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CREATE TABLE weather.stations (\\n    id text,\\n    date date,\\n    name text static,\\n    record station_record,\\n    PRIMARY KEY (id, date)\\n) WITH CLUSTERING ORDER BY (date ASC)\\n    AND additional_write_policy = '99p'\\n    AND bloom_filter_fp_chance = 0.01\\n    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\\n    AND cdc = false\\n    AND comment = ''\\n    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\\n    AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\\n    AND memtable = 'default'\\n    AND crc_check_chance = 1.0\\n    AND default_time_to_live = 0\\n    AND extensions = {}\\n    AND gc_grace_seconds = 864000\\n    AND max_index_interval = 2048\\n    AND memtable_flush_period_in_ms = 0\\n    AND min_index_interval = 128\\n    AND read_repair = 'BLOCKING'\\n    AND speculative_retry = '99p';\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1\n",
    "cass.execute(\"describe table weather.stations\").one().create_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b38dee-19fb-47e5-a3f0-735c02ee2c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.10/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-70d5faf2-510f-45fc-b257-6450fe24c39f;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.4.0 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.13.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.13.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      ":: resolution report :: resolve 1232ms :: artifacts dl 44ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.4.0 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   18  |   0   |   0   |   0   ||   18  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-70d5faf2-510f-45fc-b257-6450fe24c39f\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 18 already retrieved (0kB/33ms)\n",
      "23/11/21 00:26:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"p6\")\n",
    "         .config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.4.0')\n",
    "         .config(\"spark.sql.extensions\", \"com.datastax.spark.connector.CassandraSparkExtensions\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69b531f4-8cc4-4065-b9ae-d47591a93994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00479053</td>\n",
       "      <td>None</td>\n",
       "      <td>W BEND FIRE STN #2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00476398</td>\n",
       "      <td>None</td>\n",
       "      <td>PARK FALLS DNR HQ</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00470268</td>\n",
       "      <td>None</td>\n",
       "      <td>APPOLONIA</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00474110</td>\n",
       "      <td>None</td>\n",
       "      <td>JUNEAU</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00475525</td>\n",
       "      <td>None</td>\n",
       "      <td>MINONG 5 WSW</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>USC00479050</td>\n",
       "      <td>None</td>\n",
       "      <td>WEST BEND</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>US1WIPC0004</td>\n",
       "      <td>None</td>\n",
       "      <td>RIVER FALLS 3.0 SE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>US1WIWK0016</td>\n",
       "      <td>None</td>\n",
       "      <td>MUSKEGO 1.0 W</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>US1WIWK0086</td>\n",
       "      <td>None</td>\n",
       "      <td>WALES 0.4 NW</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>USC00475471</td>\n",
       "      <td>None</td>\n",
       "      <td>MIDDLETON</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  date                            name record\n",
       "0     USC00479053  None  W BEND FIRE STN #2               None\n",
       "1     USC00476398  None  PARK FALLS DNR HQ                None\n",
       "2     USC00470268  None  APPOLONIA                        None\n",
       "3     USC00474110  None  JUNEAU                           None\n",
       "4     USC00475525  None  MINONG 5 WSW                     None\n",
       "...           ...   ...                             ...    ...\n",
       "1308  USC00479050  None  WEST BEND                        None\n",
       "1309  US1WIPC0004  None  RIVER FALLS 3.0 SE               None\n",
       "1310  US1WIWK0016  None  MUSKEGO 1.0 W                    None\n",
       "1311  US1WIWK0086  None  WALES 0.4 NW                     None\n",
       "1312  USC00475471  None  MIDDLETON                        None\n",
       "\n",
       "[1313 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "import pandas as pd\n",
    "df = spark.read.text(\"ghcnd-stations.txt\")\n",
    "ID_df = df.withColumn(\"ID\", expr(\"substring(value, 0, 11)\"))\n",
    "STATE_df = df.withColumn(\"STATE\", expr(\"substring(value, 39, 2)\"))\n",
    "NAME_df = df.withColumn(\"NAME\", expr(\"substring(value, 42, 30)\"))\n",
    "df2 = ID_df.join(STATE_df, ['value'], how='inner')\n",
    "df2 = df2.join(NAME_df, ['value'], how='inner')\n",
    "filtered_df = df2.where(col(\"STATE\") == \"WI\")\n",
    "\n",
    "df_insert = cass.prepare(\"\"\"\n",
    "    INSERT INTO stations (id, name)\n",
    "    VALUES (?, ?)\n",
    "\"\"\")\n",
    "\n",
    "filtered_df = filtered_df.toPandas()\n",
    "for index, row in filtered_df.iterrows():\n",
    "    cass.execute(df_insert, (filtered_df[\"ID\"][index], filtered_df[\"NAME\"][index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8114a52-01a0-409e-abd1-040090aefa98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MADISON DANE CO RGNL AP       '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2\n",
    "df = pd.DataFrame(cass.execute(\"\"\"\n",
    "    SELECT name from weather.stations\n",
    "    WHERE id='USW00014837'\n",
    "\"\"\"))\n",
    "\n",
    "df[\"name\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97a2f623-d931-443a-b371-5ea7628b7ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00470273</td>\n",
       "      <td>None</td>\n",
       "      <td>UW ARBORETUM - MADISON</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  date                            name record\n",
       "0  USC00470273  None  UW ARBORETUM - MADISON           None"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3\n",
    "pd.DataFrame(cass.execute(\"\"\"\n",
    "    SELECT * from weather.stations\n",
    "    WHERE id='USC00470273'\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d1bcd0a-0718-4297-a9c8-d3ec86d61428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datacenter: datacenter1\n",
      "==========\n",
      "Address          Rack        Status State   Load            Owns                Token                                       \n",
      "                                                                                9045517454624181859                         \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             -8760787059843916800                        \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             -8142806027941716722                        \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             -7689286443503883987                        \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             -7078465038168653325                        \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             -6671435038761456971                        \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             -5853763106149106177                        \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             -5258460737188706926                        \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             -4778007224923526637                        \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             -4042091532212632996                        \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             -3381396407675720897                        \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             -2962718724765031339                        \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             -2212441484496706517                        \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             -1719198719084439365                        \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             -1163317684167515429                        \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             -751834476005903867                         \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             -227404511376000010                         \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             188233148195639869                          \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             838170076507994770                          \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             1399913494867621014                         \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             1797236347216333805                         \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             2457193372205038067                         \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             3055657063161776893                         \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             3435338824721152143                         \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             4089957709837181260                         \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             4516244211118310650                         \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             5213973125544739271                         \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             5866446037692988533                         \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             6310015025779677560                         \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             6923822554621946750                         \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             7401312136471889819                         \n",
      "172.21.0.2       rack1       Up     Normal  240.08 KiB      100.00%             8245688783963051577                         \n",
      "172.21.0.4       rack1       Up     Normal  265.83 KiB      100.00%             9045517454624181859                         \n",
      "\n",
      "  Warning: \"nodetool ring\" is used to output all the tokens of a node.\n",
      "  To view status related info of a node use \"nodetool status\" instead.\n",
      "\n",
      "\n",
      "  "
     ]
    }
   ],
   "source": [
    "#q4\n",
    "!nodetool ring weather\n",
    "# import subprocess\n",
    "# sp = subprocess.check_output(\"nodetool ring weather\", stderr=subprocess.STDOUT, shell=True)\n",
    "# sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c82ea-3e7e-4492-bd82-9c3912e439e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
